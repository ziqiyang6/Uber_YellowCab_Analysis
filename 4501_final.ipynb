{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae0f7dcf-bbce-4024-80bc-3d368bb624a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: lxml in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (5.2.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4f87dde-0109-4350-91ea-6eabab5e7942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "62de1824-053c-47fb-9b6f-044e3f30c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cae9f39d-e3fa-4ab6-b702-92eda50a805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c42e1953-bb21-412b-9782-92864ac1ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 requests 获取网页内容\n",
    "response = requests.get(url)\n",
    "if response.status_code != 200:\n",
    "    print(\"请求失败，状态码:\", response.status_code)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5672d455-316c-4474-ae1b-5f7ec22248d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data\\yellow_tripdata_2024-01.parquet  ...\n",
      "data\\yellow_tripdata_2024-01.parquet  下载完成！\n",
      "Downloading data\\yellow_tripdata_2024-02.parquet  ...\n",
      "data\\yellow_tripdata_2024-02.parquet  下载完成！\n",
      "Downloading data\\yellow_tripdata_2024-03.parquet  ...\n",
      "data\\yellow_tripdata_2024-03.parquet  下载完成！\n",
      "Downloading data\\yellow_tripdata_2024-04.parquet ...\n",
      "data\\yellow_tripdata_2024-04.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2024-05.parquet ...\n",
      "data\\yellow_tripdata_2024-05.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2024-06.parquet ...\n",
      "data\\yellow_tripdata_2024-06.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2024-07.parquet ...\n",
      "data\\yellow_tripdata_2024-07.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2024-08.parquet ...\n",
      "data\\yellow_tripdata_2024-08.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2023-01.parquet ...\n",
      "data\\yellow_tripdata_2023-01.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2023-02.parquet ...\n",
      "data\\yellow_tripdata_2023-02.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2023-03.parquet ...\n",
      "data\\yellow_tripdata_2023-03.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2023-04.parquet ...\n",
      "data\\yellow_tripdata_2023-04.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2023-05.parquet  ...\n",
      "data\\yellow_tripdata_2023-05.parquet  下载完成！\n",
      "Downloading data\\yellow_tripdata_2023-06.parquet ...\n",
      "data\\yellow_tripdata_2023-06.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2023-07.parquet  ...\n",
      "data\\yellow_tripdata_2023-07.parquet  下载完成！\n",
      "Downloading data\\yellow_tripdata_2023-08.parquet  ...\n",
      "data\\yellow_tripdata_2023-08.parquet  下载完成！\n",
      "Downloading data\\yellow_tripdata_2023-09.parquet  ...\n",
      "data\\yellow_tripdata_2023-09.parquet  下载完成！\n",
      "Downloading data\\yellow_tripdata_2023-10.parquet  ...\n",
      "data\\yellow_tripdata_2023-10.parquet  下载完成！\n",
      "Downloading data\\yellow_tripdata_2023-11.parquet  ...\n",
      "data\\yellow_tripdata_2023-11.parquet  下载完成！\n",
      "Downloading data\\yellow_tripdata_2023-12.parquet ...\n",
      "data\\yellow_tripdata_2023-12.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2022-01.parquet ...\n",
      "data\\yellow_tripdata_2022-01.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2022-02.parquet ...\n",
      "data\\yellow_tripdata_2022-02.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2022-03.parquet ...\n",
      "data\\yellow_tripdata_2022-03.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2022-04.parquet ...\n",
      "data\\yellow_tripdata_2022-04.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2022-05.parquet ...\n",
      "data\\yellow_tripdata_2022-05.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2022-06.parquet ...\n",
      "data\\yellow_tripdata_2022-06.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2022-07.parquet ...\n",
      "data\\yellow_tripdata_2022-07.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2022-08.parquet ...\n",
      "data\\yellow_tripdata_2022-08.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2022-09.parquet ...\n",
      "data\\yellow_tripdata_2022-09.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2022-10.parquet ...\n",
      "data\\yellow_tripdata_2022-10.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2022-11.parquet ...\n",
      "data\\yellow_tripdata_2022-11.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2022-12.parquet ...\n",
      "data\\yellow_tripdata_2022-12.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2021-01.parquet ...\n",
      "data\\yellow_tripdata_2021-01.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2021-02.parquet ...\n",
      "data\\yellow_tripdata_2021-02.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2021-03.parquet ...\n",
      "data\\yellow_tripdata_2021-03.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2021-04.parquet ...\n",
      "data\\yellow_tripdata_2021-04.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2021-05.parquet ...\n",
      "data\\yellow_tripdata_2021-05.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2021-06.parquet ...\n",
      "data\\yellow_tripdata_2021-06.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2021-07.parquet ...\n",
      "data\\yellow_tripdata_2021-07.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2021-08.parquet ...\n",
      "data\\yellow_tripdata_2021-08.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2021-09.parquet ...\n",
      "data\\yellow_tripdata_2021-09.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2021-10.parquet ...\n",
      "data\\yellow_tripdata_2021-10.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2021-11.parquet ...\n",
      "data\\yellow_tripdata_2021-11.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2021-12.parquet ...\n",
      "data\\yellow_tripdata_2021-12.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2020-01.parquet ...\n",
      "data\\yellow_tripdata_2020-01.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2020-02.parquet ...\n",
      "data\\yellow_tripdata_2020-02.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2020-03.parquet ...\n",
      "data\\yellow_tripdata_2020-03.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2020-04.parquet ...\n",
      "data\\yellow_tripdata_2020-04.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2020-05.parquet ...\n",
      "data\\yellow_tripdata_2020-05.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2020-06.parquet ...\n",
      "data\\yellow_tripdata_2020-06.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2020-07.parquet ...\n",
      "data\\yellow_tripdata_2020-07.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2020-08.parquet ...\n",
      "data\\yellow_tripdata_2020-08.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2020-09.parquet ...\n",
      "data\\yellow_tripdata_2020-09.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2020-10.parquet ...\n",
      "data\\yellow_tripdata_2020-10.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2020-11.parquet ...\n",
      "data\\yellow_tripdata_2020-11.parquet 下载完成！\n",
      "Downloading data\\yellow_tripdata_2020-12.parquet ...\n",
      "data\\yellow_tripdata_2020-12.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2024-01.parquet  ...\n",
      "data\\fhvhv_tripdata_2024-01.parquet  下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2024-02.parquet  ...\n",
      "data\\fhvhv_tripdata_2024-02.parquet  下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2024-03.parquet  ...\n",
      "data\\fhvhv_tripdata_2024-03.parquet  下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2024-04.parquet ...\n",
      "data\\fhvhv_tripdata_2024-04.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2024-05.parquet ...\n",
      "data\\fhvhv_tripdata_2024-05.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2024-06.parquet ...\n",
      "data\\fhvhv_tripdata_2024-06.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2024-07.parquet ...\n",
      "data\\fhvhv_tripdata_2024-07.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2024-08.parquet ...\n",
      "data\\fhvhv_tripdata_2024-08.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2023-01.parquet ...\n",
      "data\\fhvhv_tripdata_2023-01.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2023-02.parquet ...\n",
      "data\\fhvhv_tripdata_2023-02.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2023-03.parquet  ...\n",
      "data\\fhvhv_tripdata_2023-03.parquet  下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2023-04.parquet ...\n",
      "data\\fhvhv_tripdata_2023-04.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2023-05.parquet  ...\n",
      "data\\fhvhv_tripdata_2023-05.parquet  下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2023-06.parquet ...\n",
      "data\\fhvhv_tripdata_2023-06.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2023-07.parquet  ...\n",
      "data\\fhvhv_tripdata_2023-07.parquet  下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2023-08.parquet  ...\n",
      "data\\fhvhv_tripdata_2023-08.parquet  下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2023-09.parquet  ...\n",
      "data\\fhvhv_tripdata_2023-09.parquet  下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2023-10.parquet  ...\n",
      "data\\fhvhv_tripdata_2023-10.parquet  下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2023-11.parquet  ...\n",
      "data\\fhvhv_tripdata_2023-11.parquet  下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2023-12.parquet  ...\n",
      "data\\fhvhv_tripdata_2023-12.parquet  下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2022-01.parquet ...\n",
      "data\\fhvhv_tripdata_2022-01.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2022-02.parquet ...\n",
      "data\\fhvhv_tripdata_2022-02.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2022-03.parquet ...\n",
      "data\\fhvhv_tripdata_2022-03.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2022-04.parquet ...\n",
      "data\\fhvhv_tripdata_2022-04.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2022-05.parquet ...\n",
      "data\\fhvhv_tripdata_2022-05.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2022-06.parquet ...\n",
      "data\\fhvhv_tripdata_2022-06.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2022-07.parquet ...\n",
      "data\\fhvhv_tripdata_2022-07.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2022-08.parquet ...\n",
      "data\\fhvhv_tripdata_2022-08.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2022-09.parquet ...\n",
      "data\\fhvhv_tripdata_2022-09.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2022-10.parquet ...\n",
      "data\\fhvhv_tripdata_2022-10.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2022-11.parquet ...\n",
      "data\\fhvhv_tripdata_2022-11.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2022-12.parquet ...\n",
      "data\\fhvhv_tripdata_2022-12.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2021-01.parquet ...\n",
      "data\\fhvhv_tripdata_2021-01.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2021-02.parquet ...\n",
      "data\\fhvhv_tripdata_2021-02.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2021-03.parquet ...\n",
      "data\\fhvhv_tripdata_2021-03.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2021-04.parquet ...\n",
      "data\\fhvhv_tripdata_2021-04.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2021-05.parquet ...\n",
      "data\\fhvhv_tripdata_2021-05.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2021-06.parquet ...\n",
      "data\\fhvhv_tripdata_2021-06.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2021-07.parquet ...\n",
      "data\\fhvhv_tripdata_2021-07.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2021-08.parquet ...\n",
      "data\\fhvhv_tripdata_2021-08.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2021-09.parquet ...\n",
      "data\\fhvhv_tripdata_2021-09.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2021-10.parquet ...\n",
      "data\\fhvhv_tripdata_2021-10.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2021-11.parquet ...\n",
      "data\\fhvhv_tripdata_2021-11.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2021-12.parquet ...\n",
      "data\\fhvhv_tripdata_2021-12.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2020-01.parquet ...\n",
      "data\\fhvhv_tripdata_2020-01.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2020-02.parquet ...\n",
      "data\\fhvhv_tripdata_2020-02.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2020-03.parquet ...\n",
      "data\\fhvhv_tripdata_2020-03.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2020-04.parquet ...\n",
      "data\\fhvhv_tripdata_2020-04.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2020-05.parquet ...\n",
      "data\\fhvhv_tripdata_2020-05.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2020-06.parquet ...\n",
      "data\\fhvhv_tripdata_2020-06.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2020-07.parquet ...\n",
      "data\\fhvhv_tripdata_2020-07.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2020-08.parquet ...\n",
      "data\\fhvhv_tripdata_2020-08.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2020-09.parquet ...\n",
      "data\\fhvhv_tripdata_2020-09.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2020-10.parquet ...\n",
      "data\\fhvhv_tripdata_2020-10.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2020-11.parquet ...\n",
      "data\\fhvhv_tripdata_2020-11.parquet 下载完成！\n",
      "Downloading data\\fhvhv_tripdata_2020-12.parquet ...\n",
      "data\\fhvhv_tripdata_2020-12.parquet 下载完成！\n"
     ]
    }
   ],
   "source": [
    "# 使用 BeautifulSoup 解析网页内容\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "\n",
    "Yellow_Taxi_pattern = re.compile(r'yellow_tripdata_202[0-4]-\\d{2}.parquet', re.IGNORECASE)\n",
    "HVFHV_pattern = re.compile(r'fhvhv_tripdata_202[0-4]-\\d{2}.parquet', re.IGNORECASE)\n",
    "\n",
    "# 查找所有符合 Yellow Taxi 的链接\n",
    "Yellow_Taxi_links = [link.get('href') for link in soup.find_all('a', href=Yellow_Taxi_pattern)]\n",
    "HVFHV_links = [link.get('href') for link in soup.find_all('a', href=HVFHV_pattern)]\n",
    "\n",
    "# 合并两个链接列表\n",
    "all_links = Yellow_Taxi_links + HVFHV_links\n",
    "\n",
    "# 下载每个 Parquet 文件\n",
    "for link in all_links:\n",
    "    # 如果链接是相对路径，则将其转换为完整 URL\n",
    "    file_url = link if link.startswith('http') else url + link\n",
    "    file_name = os.path.join('data', file_url.split('/')[-1])\n",
    "    \n",
    "    # 下载文件\n",
    "    print(f\"Downloading {file_name} ...\")\n",
    "    file_response = requests.get(file_url)\n",
    "    \n",
    "    # 将文件内容写入本地文件\n",
    "    with open(file_name, 'wb') as file:\n",
    "        file.write(file_response.content)\n",
    "    print(f\"{file_name} 下载完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b77f1f3c-da36-48af-8637-bf38e5f78c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastparquet in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2024.5.0)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from fastparquet) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from fastparquet) (1.26.4)\n",
      "Requirement already satisfied: cramjam>=2.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from fastparquet) (2.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from fastparquet) (2024.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from fastparquet) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "151c962e-18ca-469b-9ca9-698dfc8c5d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (14.0.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyarrow) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "264aed3a-dfaa-4fca-a914-b1b12c39840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\作业\\4501\\your_file.txt\n",
      "C:\\Users\\Lenovo\\作业\\4501\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 获取文件的绝对路径\n",
    "file_path = Path(\"your_file.txt\").resolve()\n",
    "print(file_path)\n",
    "\n",
    "# 获取当前工作目录\n",
    "current_directory = Path.cwd()\n",
    "print(current_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1b2e9c9e-89b6-45e7-8fbc-465e3fced796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         1  2020-12-01 00:07:13   2020-12-01 00:18:12              1.0   \n",
      "1         1  2020-12-01 00:41:19   2020-12-01 00:49:45              1.0   \n",
      "2         2  2020-12-01 00:33:40   2020-12-01 01:00:35              1.0   \n",
      "3         2  2020-12-01 00:02:15   2020-12-01 00:13:09              1.0   \n",
      "4         2  2020-12-01 00:37:42   2020-12-01 00:45:11              1.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           7.60         1.0                  N           138           263   \n",
      "1           1.60         1.0                  N           140           263   \n",
      "2          16.74         2.0                  N           132           164   \n",
      "3           4.16         1.0                  N           238            48   \n",
      "4           2.22         1.0                  N           238            41   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             1         21.5    3.0      0.5        2.50          6.12   \n",
      "1             1          8.0    3.0      0.5        2.95          0.00   \n",
      "2             1         52.0    0.0      0.5        2.50          6.12   \n",
      "3             1         14.0    0.5      0.5        1.00          0.00   \n",
      "4             2          8.5    0.5      0.5        0.00          0.00   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
      "0                    0.3         33.92                   2.5          NaN  \n",
      "1                    0.3         14.75                   2.5          NaN  \n",
      "2                    0.3         63.92                   2.5          NaN  \n",
      "3                    0.3         18.80                   2.5          NaN  \n",
      "4                    0.3          9.80                   0.0          NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    df = pd.read_parquet(r'C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2020-12.parquet', engine='pyarrow')\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"读取 Parquet 文件失败: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b7ee3f62-0205-41e7-bba0-b7a6ed7ef60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
      "0            HV0003               B02764               B02764   \n",
      "1            HV0003               B02764               B02764   \n",
      "2            HV0005               B02510                 None   \n",
      "3            HV0003               B02883               B02883   \n",
      "4            HV0003               B02883               B02883   \n",
      "\n",
      "     request_datetime   on_scene_datetime     pickup_datetime  \\\n",
      "0 2020-12-01 00:08:29 2020-12-01 00:11:29 2020-12-01 00:13:22   \n",
      "1 2020-12-01 00:44:34 2020-12-01 00:47:00 2020-12-01 00:47:19   \n",
      "2 2020-12-01 00:10:54                 NaT 2020-12-01 00:17:14   \n",
      "3 2020-11-30 23:58:37 2020-12-01 00:00:01 2020-12-01 00:01:16   \n",
      "4 2020-12-01 00:25:44 2020-12-01 00:30:41 2020-12-01 00:32:03   \n",
      "\n",
      "     dropoff_datetime  PULocationID  DOLocationID  trip_miles  ...  sales_tax  \\\n",
      "0 2020-12-01 00:33:53            94            75        6.90  ...       1.79   \n",
      "1 2020-12-01 00:57:01            75           164        3.73  ...       1.41   \n",
      "2 2020-12-01 00:37:42            87           179       11.73  ...       2.58   \n",
      "3 2020-12-01 00:20:26            80            92        8.34  ...       1.77   \n",
      "4 2020-12-01 00:45:18            92            92        2.77  ...       1.00   \n",
      "\n",
      "   congestion_surcharge  airport_fee  tips  driver_pay  shared_request_flag  \\\n",
      "0                  0.00          NaN  0.00       17.91                    N   \n",
      "1                  2.75          NaN  1.88        8.99                    N   \n",
      "2                  2.75          NaN  0.00       23.30                    N   \n",
      "3                  0.00          NaN  2.82       18.82                    N   \n",
      "4                  0.00          NaN  0.00        9.70                    N   \n",
      "\n",
      "   shared_match_flag  access_a_ride_flag  wav_request_flag wav_match_flag  \n",
      "0                  N                                     N              N  \n",
      "1                  N                                     N              N  \n",
      "2                  N                   N                 N              N  \n",
      "3                  N                                     N              N  \n",
      "4                  N                                     N              N  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    df = pd.read_parquet(r'C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-12.parquet', engine='pyarrow')\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"读取 Parquet 文件失败: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5363471c-641f-48ae-96f0-57441aef4b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-01.parquet，共 14582520 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-02.parquet，共 15743610 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-03.parquet，共 9836781 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-04.parquet，共 3102835 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-05.parquet，共 4359377 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-06.parquet，共 5114308 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-07.parquet，共 7081522 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-08.parquet，共 7856499 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-09.parquet，共 8847755 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-10.parquet，共 9797775 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-11.parquet，共 8375281 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-12.parquet，共 8486416 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-01.parquet，共 8704128 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-02.parquet，共 8290758 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-03.parquet，共 10173376 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-04.parquet，共 10238382 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-05.parquet，共 10808415 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-06.parquet，共 10747390 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-07.parquet，共 10704366 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-08.parquet，共 10196747 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-09.parquet，共 10557442 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-10.parquet，共 12086389 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-11.parquet，共 11819597 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-12.parquet，共 11802074 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-01.parquet，共 10826336 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-02.parquet，共 11440898 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-03.parquet，共 13136268 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-04.parquet，共 13010980 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-05.parquet，共 13325434 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-06.parquet，共 13049858 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-07.parquet，共 12575713 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-08.parquet，共 12500703 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-09.parquet，共 12902315 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-10.parquet，共 14102892 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-11.parquet，共 12968005 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-12.parquet，共 14007908 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-01.parquet，共 13580152 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-02.parquet，共 13280939 行数据。\n",
      "无法读取文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-03.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-04.parquet，共 13998413 行数据。\n",
      "无法读取文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-05.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-06.parquet，共 13811993 行数据。\n",
      "无法读取文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-07.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法读取文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-08.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法读取文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-09.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法读取文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-10.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法读取文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-11.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法读取文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-12.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法读取文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2024-01.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法读取文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2024-02.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法读取文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2024-03.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2024-04.parquet，共 14704197 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2024-05.parquet，共 15538267 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2024-06.parquet，共 15158032 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2024-07.parquet，共 14328764 行数据。\n",
      "筛选后的 Uber 数据已写入文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2024-08.parquet，共 14107392 行数据。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# 定义 Uber 标识符\n",
    "uber_identifiers = ['HV0003']\n",
    "\n",
    "# 获取所有 Parquet 文件路径\n",
    "file_paths = glob.glob(r'C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_202[0-4]-*.parquet')\n",
    "\n",
    "# 用于存储筛选后的数据\n",
    "filtered_data = []\n",
    "\n",
    "# 遍历文件路径并进行筛选\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        # 尝试读取文件\n",
    "        df = pd.read_parquet(file_path, engine='pyarrow')\n",
    "        \n",
    "        # 筛选出包含 Uber 行程的数据\n",
    "        uber_data = df[df['hvfhs_license_num'].isin(uber_identifiers)]\n",
    "        \n",
    "        # 将筛选后的数据写回原文件（覆盖）\n",
    "        uber_data.to_parquet(file_path, index=False, engine='pyarrow')\n",
    "        \n",
    "        print(f\"筛选后的 Uber 数据已写入文件 {file_path}，共 {len(uber_data)} 行数据。\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"无法读取文件 {file_path}：{e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94768a17-f0f3-4cb2-b328-076e9c69dff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-01.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2020-01.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-02.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2020-02.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-03.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2020-03.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-04.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2020-04.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-05.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2020-05.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-06.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2020-06.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-07.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2020-07.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-08.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2020-08.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-09.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2020-09.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-10.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2020-10.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-11.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2020-11.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2020-12.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2020-12.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-01.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2021-01.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-02.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2021-02.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-03.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2021-03.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-04.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2021-04.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-05.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2021-05.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-06.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2021-06.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-07.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2021-07.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-08.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2021-08.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-09.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2021-09.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-10.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2021-10.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-11.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2021-11.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2021-12.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2021-12.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-01.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2022-01.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-02.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2022-02.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-03.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2022-03.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-04.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2022-04.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-05.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2022-05.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-06.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2022-06.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-07.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2022-07.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-08.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2022-08.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-09.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2022-09.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-10.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2022-10.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-11.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2022-11.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2022-12.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2022-12.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-01.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2023-01.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-02.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2023-02.parquet\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-03.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-04.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2023-04.parquet\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-05.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-06.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2023-06.parquet\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-07.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-08.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-09.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-10.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-11.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2023-12.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2024-01.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2024-02.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2024-03.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2024-04.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2024-04.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2024-05.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2024-05.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2024-06.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2024-06.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2024-07.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2024-07.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_2024-08.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data\\fhvhv_tripdata_2024-08.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 获取所有 HVFHV 数据集的文件路径\n",
    "file_paths = glob.glob(r'C:\\Users\\Lenovo\\作业\\4501\\data\\fhvhv_tripdata_202[0-4]-*.parquet')\n",
    "\n",
    "# 创建新文件夹 'Sample_data'，如果不存在则创建\n",
    "sample_folder = r'C:\\Users\\Lenovo\\作业\\4501\\Sample_data'\n",
    "os.makedirs(sample_folder, exist_ok=True)\n",
    "\n",
    "# 抽样大小\n",
    "sample_size = 385\n",
    "\n",
    "# 遍历每个文件\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        # 读取文件\n",
    "        df = pd.read_parquet(file_path, engine='pyarrow')\n",
    "        \n",
    "        # 筛选 Uber 行程数据\n",
    "        uber_data = df[df['hvfhs_license_num'].isin(uber_identifiers)]\n",
    "        \n",
    "        # 随机抽样 385 行\n",
    "        sample_data = uber_data.sample(n=sample_size, random_state=42)\n",
    "        \n",
    "        # 创建新文件路径\n",
    "        file_name = os.path.basename(file_path)\n",
    "        sample_file_path = os.path.join(sample_folder, file_name)\n",
    "        \n",
    "        # 将抽样数据写入新文件夹中的同名文件\n",
    "        sample_data.to_parquet(sample_file_path, index=False, engine='pyarrow')\n",
    "        \n",
    "        print(f\"{file_path} 中已抽取 {sample_size} 行数据，并保存至 {sample_file_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        # 跳过无法读取的文件，并打印错误信息\n",
    "        print(f\"无法处理文件 {file_path}：{e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be929b56-9363-4cfc-9ae7-94b3ab3516b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2020-01.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2020-01.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2020-02.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2020-02.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2020-03.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2020-03.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2020-04.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2020-04.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2020-05.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2020-05.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2020-06.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2020-06.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2020-07.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2020-07.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2020-08.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2020-08.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2020-09.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2020-09.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2020-10.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2020-10.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2020-11.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2020-11.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2020-12.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2020-12.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2021-01.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2021-01.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2021-02.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2021-02.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2021-03.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2021-03.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2021-04.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2021-04.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2021-05.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2021-05.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2021-06.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2021-06.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2021-07.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2021-07.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2021-08.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2021-08.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2021-09.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2021-09.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2021-10.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2021-10.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2021-11.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2021-11.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2021-12.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2021-12.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2022-01.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2022-01.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2022-02.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2022-02.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2022-03.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2022-03.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2022-04.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2022-04.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2022-05.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2022-05.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2022-06.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2022-06.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2022-07.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2022-07.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2022-08.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2022-08.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2022-09.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2022-09.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2022-10.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2022-10.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2022-11.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2022-11.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2022-12.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2022-12.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2023-01.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2023-01.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2023-02.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2023-02.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2023-03.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2023-03.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2023-04.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2023-04.parquet\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2023-05.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2023-06.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2023-06.parquet\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2023-07.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2023-08.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2023-09.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2023-10.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2023-11.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2023-12.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2023-12.parquet\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2024-01.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2024-02.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "无法处理文件 C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2024-03.parquet：Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2024-04.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2024-04.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2024-05.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2024-05.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2024-06.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2024-06.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2024-07.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2024-07.parquet\n",
      "C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_2024-08.parquet 中已抽取 385 行数据，并保存至 C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2024-08.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "# 获取所有 HVFHV 数据集的文件路径\n",
    "file_paths = glob.glob(r'C:\\Users\\Lenovo\\作业\\4501\\data\\yellow_tripdata_202[0-4]-*.parquet')\n",
    "\n",
    "# 创建新文件夹 'Sample_data'，如果不存在则创建\n",
    "sample_folder = r'C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow'\n",
    "os.makedirs(sample_folder, exist_ok=True)\n",
    "\n",
    "# 抽样大小\n",
    "sample_size = 385\n",
    "\n",
    "# 遍历每个文件\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        # 读取文件\n",
    "        df = pd.read_parquet(file_path, engine='pyarrow')\n",
    "        \n",
    "        # 随机抽样 385 行\n",
    "        sample_data = uber_data.sample(n=sample_size, random_state=42)\n",
    "        \n",
    "        # 创建新文件路径\n",
    "        file_name = os.path.basename(file_path)\n",
    "        sample_file_path = os.path.join(sample_folder, file_name)\n",
    "        \n",
    "        # 将抽样数据写入新文件夹中的同名文件\n",
    "        sample_data.to_parquet(sample_file_path, index=False, engine='pyarrow')\n",
    "        \n",
    "        print(f\"{file_path} 中已抽取 {sample_size} 行数据，并保存至 {sample_file_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        # 跳过无法读取的文件，并打印错误信息\n",
    "        print(f\"无法处理文件 {file_path}：{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d021a1ad-9d87-4e6e-9435-fda966e2e899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
      "0            HV0003               B03404               B03404   \n",
      "1            HV0003               B03404               B03404   \n",
      "2            HV0003               B03404               B03404   \n",
      "3            HV0003               B03404               B03404   \n",
      "4            HV0003               B03404               B03404   \n",
      "\n",
      "     request_datetime   on_scene_datetime     pickup_datetime  \\\n",
      "0 2024-08-26 19:27:31 2024-08-26 19:30:27 2024-08-26 19:30:47   \n",
      "1 2024-08-10 14:01:58 2024-08-10 14:05:53 2024-08-10 14:06:14   \n",
      "2 2024-08-25 09:11:10 2024-08-25 09:12:41 2024-08-25 09:14:29   \n",
      "3 2024-08-01 22:01:46 2024-08-01 22:08:17 2024-08-01 22:08:33   \n",
      "4 2024-08-15 11:56:40 2024-08-15 11:57:10 2024-08-15 11:58:30   \n",
      "\n",
      "     dropoff_datetime  PULocationID  DOLocationID  trip_miles  ...  sales_tax  \\\n",
      "0 2024-08-26 19:33:49           123           123        0.54  ...       0.79   \n",
      "1 2024-08-10 14:48:38           213           164       11.62  ...       5.47   \n",
      "2 2024-08-25 09:26:03            48           239        2.52  ...       1.25   \n",
      "3 2024-08-01 22:41:01           142           217        8.10  ...       3.01   \n",
      "4 2024-08-15 12:40:01           162           186        2.24  ...       2.78   \n",
      "\n",
      "   congestion_surcharge  airport_fee  tips  driver_pay  shared_request_flag  \\\n",
      "0                  0.00          0.0   0.0        5.39                    N   \n",
      "1                  2.75          0.0   0.0       40.52                    N   \n",
      "2                  2.75          0.0   0.0       10.18                    N   \n",
      "3                  2.75          0.0   0.0       29.95                    N   \n",
      "4                  2.75          0.0   0.0       29.18                    N   \n",
      "\n",
      "   shared_match_flag  access_a_ride_flag  wav_request_flag wav_match_flag  \n",
      "0                  N                   N                 N              N  \n",
      "1                  N                   N                 N              N  \n",
      "2                  N                   N                 N              N  \n",
      "3                  N                   N                 N              N  \n",
      "4                  N                   N                 N              Y  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_parquet(r'C:\\Users\\Lenovo\\作业\\4501\\Sample_data_yellow\\yellow_tripdata_2020-12.parquet', engine='pyarrow')\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"读取 Parquet 文件失败: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bffa2bdd-da79-4114-a12f-75979015135b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['OBJECTID', 'Shape_Leng', 'Shape_Area', 'zone', 'LocationID', 'borough',\n",
      "       'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 加载包含区域信息的 Shapefile 文件\n",
    "zone_gdf = gpd.read_file(\"taxi_zones.shp\")\n",
    "\n",
    "# 查看列名\n",
    "print(zone_gdf.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13556c2d-0899-4e6b-9062-4e4bacba7a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 加载包含区域信息的shapefile文件\n",
    "zone_gdf = gpd.read_file(\"taxi_zones.shp\")\n",
    "\n",
    "# 计算每个区域的中心点，获得经纬度\n",
    "zone_gdf['centroid'] = zone_gdf.geometry.centroid\n",
    "zone_gdf['latitude'] = zone_gdf['centroid'].y\n",
    "zone_gdf['longitude'] = zone_gdf['centroid'].x\n",
    "\n",
    "# 选择需要的列：location_id, latitude, longitude\n",
    "zone_gdf = zone_gdf[['LocationID', 'latitude', 'longitude']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2efce6de-7bb3-4d6a-9cde-c83485fc215e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'fare_amount'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 39\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# 保留必要的列\u001b[39;00m\n\u001b[0;32m     35\u001b[0m relevant_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVendorID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtpep_pickup_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtpep_dropoff_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrip_miles\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfare_amount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude_pickup\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude_pickup\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude_dropoff\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude_dropoff\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     38\u001b[0m ]\n\u001b[1;32m---> 39\u001b[0m df \u001b[38;5;241m=\u001b[39m df[relevant_columns]\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# 重命名列\u001b[39;00m\n\u001b[0;32m     42\u001b[0m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtpep_pickup_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPUDatetime\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtpep_dropoff_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDODatetime\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrip_miles\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrip_distance\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfare_amount\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfare\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     47\u001b[0m }, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'fare_amount'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 指定包含所有 Parquet 文件的文件夹路径\n",
    "folder_path = r'C:\\Users\\Lenovo\\作业\\4501\\Sample_data'\n",
    "all_files = glob.glob(os.path.join(folder_path, \"*.parquet\"))\n",
    "\n",
    "# 加载 Shapefile 文件并计算每个区域的质心，获取经纬度\n",
    "zone_gdf = gpd.read_file(\"nyc_zones.shp\")\n",
    "zone_gdf['centroid'] = zone_gdf.geometry.centroid\n",
    "zone_gdf['latitude'] = zone_gdf['centroid'].y\n",
    "zone_gdf['longitude'] = zone_gdf['centroid'].x\n",
    "\n",
    "# 确保列名与 Parquet 文件中的一致\n",
    "zone_gdf = zone_gdf[['LocationID', 'latitude', 'longitude']]\n",
    "\n",
    "# 定义经纬度范围\n",
    "lat_min, lon_min = 40.560445, -74.242330\n",
    "lat_max, lon_max = 40.908524, -73.717047\n",
    "\n",
    "for file in all_files:\n",
    "    # 加载 Parquet 文件\n",
    "    df = pd.read_parquet(file)\n",
    "    \n",
    "    # 将区域中心点与数据中的位置 ID 匹配，获取经纬度\n",
    "    df = df.merge(zone_gdf, how='left', left_on='PULocationID', right_on='LocationID', suffixes=('', '_pickup'))\n",
    "    df = df.merge(zone_gdf, how='left', left_on='DOLocationID', right_on='LocationID', suffixes=('_pickup', '_dropoff'))\n",
    "\n",
    "    # 删除起点和终点相同且距离为零的记录\n",
    "    df = df[~((df['PULocationID'] == df['DOLocationID']) & (df['trip_miles'] == 0))]\n",
    "\n",
    "    # 保留必要的列\n",
    "    relevant_columns = [\n",
    "        'VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'trip_miles', \n",
    "        'fare_amount', 'latitude_pickup', 'longitude_pickup', 'latitude_dropoff', 'longitude_dropoff'\n",
    "    ]\n",
    "    df = df[relevant_columns]\n",
    "\n",
    "    # 重命名列\n",
    "    df.rename(columns={\n",
    "        'tpep_pickup_datetime': 'PUDatetime',\n",
    "        'tpep_dropoff_datetime': 'DODatetime',\n",
    "        'trip_miles': 'trip_distance',\n",
    "        'fare_amount': 'fare'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # 设置每列合适的数据类型\n",
    "    df['PUDatetime'] = pd.to_datetime(df['PUDatetime'])\n",
    "    df['DODatetime'] = pd.to_datetime(df['DODatetime'])\n",
    "    df['trip_distance'] = df['trip_distance'].astype(float)\n",
    "    df['fare'] = df['fare'].astype(float)\n",
    "\n",
    "    # 过滤掉不在指定经纬度范围内的记录\n",
    "    df = df[\n",
    "        (df['latitude_pickup'].between(lat_min, lat_max)) & \n",
    "        (df['longitude_pickup'].between(lon_min, lon_max)) &\n",
    "        (df['latitude_dropoff'].between(lat_min, lat_max)) &\n",
    "        (df['longitude_dropoff'].between(lon_min, lon_max))\n",
    "    ]\n",
    "\n",
    "    # 将清理后的数据保存为新的 Parquet 文件，文件名前加上前缀\n",
    "    output_file = os.path.join(folder_path, \"cleaned_\" + os.path.basename(file))\n",
    "    df.to_parquet(output_file, index=False)\n",
    "    print(f\"清理完成并保存: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba81b7-0c30-4713-951f-180acace4cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv(\"daily_weather_data.csv\")  # 加载每日天气数据\n",
    "\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
    "\n",
    "weather_df.set_index('date', inplace=True)\n",
    "hourly_weather_df = weather_df.resample('H').interpolate(method='linear')\n",
    "\n",
    "hourly_weather_df.to_csv(\"hourly_weather_data.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
